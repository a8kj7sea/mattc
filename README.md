# Mattc

A tokenizer converts raw input text into a sequence of meaningful tokens by applying rules to identify language elements and report lexical errors.
